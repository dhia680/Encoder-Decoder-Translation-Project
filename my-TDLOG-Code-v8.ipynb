{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **I. Imports**"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T21:19:12.214289Z","iopub.status.busy":"2024-01-14T21:19:12.213417Z","iopub.status.idle":"2024-01-14T21:19:12.226817Z","shell.execute_reply":"2024-01-14T21:19:12.226124Z","shell.execute_reply.started":"2024-01-14T21:19:12.214258Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import random\n","import string\n","import re\n","import time \n","import tensorflow as tf\n","import tensorflow.data as tf_data   #not used now\n","import tensorflow.strings as tf_strings   #not used now\n","\n","import tensorflow.keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import TextVectorization\n","\n","import numpy as np\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.losses import sparse_categorical_crossentropy\n","from tensorflow.keras.optimizers import RMSprop\n","from gensim.models import Word2Vec\n","\n","# import keras.ops as ops\n","import joblib"]},{"cell_type":"markdown","metadata":{},"source":["#### **Checking GPU availabiliy**"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T21:19:12.231510Z","iopub.status.busy":"2024-01-14T21:19:12.230874Z","iopub.status.idle":"2024-01-14T21:19:12.243178Z","shell.execute_reply":"2024-01-14T21:19:12.242218Z","shell.execute_reply.started":"2024-01-14T21:19:12.231485Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 10520094975519231041\n","xla_global_id: -1\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 14626652160\n","locality {\n","  bus_id: 1\n","  links {\n","    link {\n","      device_id: 1\n","      type: \"StreamExecutor\"\n","      strength: 1\n","    }\n","  }\n","}\n","incarnation: 12785755483320340023\n","physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n","xla_global_id: 416903419\n",", name: \"/device:GPU:1\"\n","device_type: \"GPU\"\n","memory_limit: 14626652160\n","locality {\n","  bus_id: 1\n","  links {\n","    link {\n","      type: \"StreamExecutor\"\n","      strength: 1\n","    }\n","  }\n","}\n","incarnation: 16816183578209216759\n","physical_device_desc: \"device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\"\n","xla_global_id: 2144165316\n","]\n"]}],"source":["# from keras import backend as K\n","# K.tensorflow_backend._get_available_gpus()\n","from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"]},{"cell_type":"markdown","metadata":{},"source":["# **II. Data Extraction & Visualization**"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T21:19:12.245763Z","iopub.status.busy":"2024-01-14T21:19:12.245425Z","iopub.status.idle":"2024-01-14T21:19:12.253385Z","shell.execute_reply":"2024-01-14T21:19:12.252461Z","shell.execute_reply.started":"2024-01-14T21:19:12.245721Z"},"trusted":true},"outputs":[],"source":["file = '/kaggle/input/tabdelimited-englisharabic-sentence-pairs/fra.txt'"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T21:19:12.276712Z","iopub.status.busy":"2024-01-14T21:19:12.276465Z","iopub.status.idle":"2024-01-14T21:19:12.603172Z","shell.execute_reply":"2024-01-14T21:19:12.602285Z","shell.execute_reply.started":"2024-01-14T21:19:12.276691Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>en</th>\n","      <th>fr</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Go.</td>\n","      <td>Va !</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Hi.</td>\n","      <td>Salut !</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Run!</td>\n","      <td>Cours !</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Run!</td>\n","      <td>Courez !</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Wow!</td>\n","      <td>Ça alors !</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     en          fr\n","0   Go.        Va !\n","1   Hi.     Salut !\n","2  Run!     Cours !\n","3  Run!    Courez !\n","4  Wow!  Ça alors !"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# df_raw = pd.read_csv(\"fra.txt\", delimiter='\\t', error_bad_lines=False, header=None, names=['en', 'fr'], index_col=False)\n","df_raw = pd.read_csv(file, delimiter='\\t', encoding='utf-8', header=None, names=['en', 'fr'], index_col=False)\n","df_raw.head()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T21:19:12.604863Z","iopub.status.busy":"2024-01-14T21:19:12.604544Z","iopub.status.idle":"2024-01-14T21:19:12.834929Z","shell.execute_reply":"2024-01-14T21:19:12.833941Z","shell.execute_reply.started":"2024-01-14T21:19:12.604837Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of sentences : 160538\n","English longest sentence: 286\n","French longest sentence: 349\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_42/3154719994.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n","  print(f\"Number of sentences : {df_raw1.count()[0]}\")\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>en</th>\n","      <th>fr</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Go.</td>\n","      <td>Va !</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Hi.</td>\n","      <td>Salut !</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Run!</td>\n","      <td>Cours !</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Run!</td>\n","      <td>Courez !</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Wow!</td>\n","      <td>Ça alors !</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     en          fr\n","0   Go.        Va !\n","1   Hi.     Salut !\n","2  Run!     Cours !\n","3  Run!    Courez !\n","4  Wow!  Ça alors !"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"Choosing a subset of the dataframe to work with (eventually choosing the whole dataframe)\"\"\"\n","lang1 = 'en'\n","lang2 = 'fr'  #subject to changes\n","# Create a new DataFrame with every fourth row (50% of th data)\n","# df_raw1 = df_raw.iloc[::2, :].reset_index(drop=True)\n","df_raw1 = df_raw\n","print(f\"Number of sentences : {df_raw1.count()[0]}\")\n","print(f\"English longest sentence: {df_raw1[lang1].str.len().max()}\")\n","print(f\"French longest sentence: {df_raw1[lang2].str.len().max()}\") \n","df_raw1.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T21:19:12.836206Z","iopub.status.busy":"2024-01-14T21:19:12.835920Z","iopub.status.idle":"2024-01-14T21:19:12.842042Z","shell.execute_reply":"2024-01-14T21:19:12.841007Z","shell.execute_reply.started":"2024-01-14T21:19:12.836183Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["It may be impossible to get a completely error-free corpus due to the nature of this kind of collaborative effort. However, if we encourage members to contribute sentences in their own languages rather than experiment in languages they are learning, we might be able to minimize errors. \n","\n","Il est peut-être impossible d'obtenir un Corpus complètement dénué de fautes, étant donnée la nature de ce type d'entreprise collaborative. Cependant, si nous encourageons les membres à produire des phrases dans leurs propres langues plutôt que d'expérimenter dans les langues qu'ils apprennent, nous pourrions être en mesure de réduire les erreurs.\n"]}],"source":["print(df_raw1[\"en\"][len(df_raw1)-1],\"\\n\")\n","print(df_raw1[\"fr\"][len(df_raw1)-1])"]},{"cell_type":"markdown","metadata":{},"source":["# **III. Data Preprocessing**"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T21:19:12.844743Z","iopub.status.busy":"2024-01-14T21:19:12.844436Z","iopub.status.idle":"2024-01-14T21:19:12.852324Z","shell.execute_reply":"2024-01-14T21:19:12.850703Z","shell.execute_reply.started":"2024-01-14T21:19:12.844712Z"},"trusted":true},"outputs":[],"source":["#Returning a list of tuples (corresponding eng-fre sentences)\n","def Create_pairs(dataframe):\n","    text_pairs = [(row['en'], \"[start] \"+row['fr']+\" [end]\") for index, row in dataframe.iterrows()] \n","    return text_pairs"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T21:19:12.854038Z","iopub.status.busy":"2024-01-14T21:19:12.853688Z","iopub.status.idle":"2024-01-14T21:19:12.863511Z","shell.execute_reply":"2024-01-14T21:19:12.862478Z","shell.execute_reply.started":"2024-01-14T21:19:12.854009Z"},"trusted":true},"outputs":[],"source":["##########Spacy is useless for now#############\n","# import spacy\n","# # nlp = spacy.load('en',disable=['parser', 'tagger','ner'])  #deprecated on spacy v3\n","# # nlp = spacy.load('en_core_web_sm')\n","# nlp = spacy.load(\"en_core_web_sm\", exclude=[\"parser\", \"tagger\", \"ner\"])\n","# nlp.max_length = 1198623\n","\n","def separate_punc(doc_text):\n","    return [token.text.lower() for token in nlp(doc_text) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T21:19:12.865576Z","iopub.status.busy":"2024-01-14T21:19:12.864921Z","iopub.status.idle":"2024-01-14T21:19:22.521775Z","shell.execute_reply":"2024-01-14T21:19:22.521019Z","shell.execute_reply.started":"2024-01-14T21:19:12.865536Z"},"trusted":true},"outputs":[],"source":["#Create the pairs\n","text_pairs = Create_pairs(df_raw1)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T21:19:22.523152Z","iopub.status.busy":"2024-01-14T21:19:22.522852Z","iopub.status.idle":"2024-01-14T21:19:22.528409Z","shell.execute_reply":"2024-01-14T21:19:22.527623Z","shell.execute_reply.started":"2024-01-14T21:19:22.523127Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(\"You're upset.\", '[start] Tu es contrariée. [end]')\n","\n","('Everybody is supposed to know the law, but few people really do.', '[start] Tout le monde est censé connaître les lois, mais très peu de gens les connaissent vraiment. [end]')\n","\n","('The GDP of China still pales in comparison with that of the US.', '[start] Le PIB de la Chine est encore dérisoire en comparaison de celui des États-Unis. [end]')\n","\n"]}],"source":["#How sentence pairs look like\n","for i in range(3):\n","    pair = random.choice(text_pairs)\n","    print(pair)\n","    print()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T21:19:22.529569Z","iopub.status.busy":"2024-01-14T21:19:22.529340Z","iopub.status.idle":"2024-01-14T21:19:22.548072Z","shell.execute_reply":"2024-01-14T21:19:22.547257Z","shell.execute_reply.started":"2024-01-14T21:19:22.529549Z"},"trusted":true},"outputs":[],"source":["# en_sentences = [en_sentence for en_sentence, _ in text_pairs[:20000]]\n","# all_en_sentences = ' '.join(en_sentences)\n","# eng_doc = nlp(all_en_sentences)\n","# unique_eng_tokens = set(token.text for token in eng_doc)\n","# len(unique_eng_tokens)\n","\n","## ---> All english sentences (~160K) contain together ~14.5K unique tokens\n","## ---> All french sentences (~160K) contain together more than 25k unique tokens"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T21:19:22.549441Z","iopub.status.busy":"2024-01-14T21:19:22.549187Z","iopub.status.idle":"2024-01-14T21:19:22.702252Z","shell.execute_reply":"2024-01-14T21:19:22.701430Z","shell.execute_reply.started":"2024-01-14T21:19:22.549419Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["160538 total text pairs\n","112378 training pairs\n","24080 validation pairs\n","24080 test pairs\n","THIS TRAIN TEST VAL SPLIT IS NOT USED YET (cf val=0.2 : automatic split in the keras model def)\n"]}],"source":["\"\"\"\n","Now, let's split the sentence pairs into a training set, a validation set,\n","and a test set.\n","\"\"\"\n","random.seed(123)\n","random.shuffle(text_pairs)\n","num_val_samples = int(0.15 * len(text_pairs))\n","num_train_samples = len(text_pairs) - 2 * num_val_samples\n","train_pairs = text_pairs[:num_train_samples]\n","val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n","test_pairs = text_pairs[num_train_samples + num_val_samples :]\n","\n","print(f\"{len(text_pairs)} total text pairs\")\n","print(f\"{len(train_pairs)} training pairs\")\n","print(f\"{len(val_pairs)} validation pairs\")\n","print(f\"{len(test_pairs)} test pairs\")\n","print(\"THIS TRAIN TEST VAL SPLIT IS NOT USED YET (cf val=0.2 : automatic split in the keras model def)\")"]},{"cell_type":"markdown","metadata":{},"source":["### **TextVecotrization: tokenization & index representation**"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T21:19:22.706316Z","iopub.status.busy":"2024-01-14T21:19:22.706047Z","iopub.status.idle":"2024-01-14T21:19:22.712702Z","shell.execute_reply":"2024-01-14T21:19:22.712017Z","shell.execute_reply.started":"2024-01-14T21:19:22.706294Z"},"trusted":true},"outputs":[],"source":["strip_chars = list(string.punctuation)\n","eng_strip_chars = '  '.join(strip_chars)\n","strip_chars.remove('[')\n","strip_chars.remove(']')\n","fre_strip_chars = '  '.join(strip_chars)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T21:19:22.714051Z","iopub.status.busy":"2024-01-14T21:19:22.713718Z","iopub.status.idle":"2024-01-14T21:19:22.731044Z","shell.execute_reply":"2024-01-14T21:19:22.730028Z","shell.execute_reply.started":"2024-01-14T21:19:22.714020Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Characters to be deleted from english sequences:  !  \"  #  $  %  &  '  (  )  *  +  ,  -  .  /  :  ;  <  =  >  ?  @  [  \\  ]  ^  _  `  {  |  }  ~\n","Characters to be deleted from french sequences:  !  \"  #  $  %  &  '  (  )  *  +  ,  -  .  /  :  ;  <  =  >  ?  @  \\  ^  _  `  {  |  }  ~\n","tf.Tensor(b'[start] vas y cours plus vite  [end]', shape=(), dtype=string)\n"]}],"source":["print(f\"Characters to be deleted from english sequences:  {eng_strip_chars}\")\n","print(f\"Characters to be deleted from french sequences:  {fre_strip_chars}\")\n","\n","#There's a default standardization done by keras.layers.TextVectorization (we'll apply it to english sentences)\n","#But it deletes also '[' and ']' symbols, that's why we specify a custom standardization for french sentences (we want to keep [start] and [end] tokens)\n","def custom_standardization(input_string):\n","    lowercase = tf_strings.lower(input_string)\n","    return tf_strings.regex_replace(lowercase, \"[%s]\" % re.escape(''.join(strip_chars)), \"\")\n","\n","#testing the function\n","print(custom_standardization(\"[start] Vas y, cours 'plus' vite !! [end]\"))"]},{"cell_type":"markdown","metadata":{},"source":["#### Vectorization Parameters"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T21:19:22.732596Z","iopub.status.busy":"2024-01-14T21:19:22.732321Z","iopub.status.idle":"2024-01-14T21:19:22.736278Z","shell.execute_reply":"2024-01-14T21:19:22.735465Z","shell.execute_reply.started":"2024-01-14T21:19:22.732575Z"},"trusted":true},"outputs":[],"source":["vocab_size = 20000\n","sequence_length = 20 #20 suggested in litterature"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T21:19:22.737671Z","iopub.status.busy":"2024-01-14T21:19:22.737422Z","iopub.status.idle":"2024-01-14T21:19:22.768807Z","shell.execute_reply":"2024-01-14T21:19:22.767985Z","shell.execute_reply.started":"2024-01-14T21:19:22.737649Z"},"trusted":true},"outputs":[],"source":["\"\"\"Vectorizing text data using Keras TextVectorization -> Representing unique tokens with indices in a dictionnary\"\"\"\n","\n","#Default standardization for eng (strip string.punctuations )\n","eng_vectorization = TextVectorization(\n","    max_tokens=vocab_size,\n","    output_mode=\"int\",\n","    output_sequence_length=sequence_length,\n",")\n","#customized for french\n","fre_vectorization = TextVectorization(\n","    max_tokens=vocab_size,\n","    output_mode=\"int\",\n","    output_sequence_length=sequence_length + 1,\n","    standardize=custom_standardization,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### Training the vectorizers"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T21:19:22.770560Z","iopub.status.busy":"2024-01-14T21:19:22.769983Z","iopub.status.idle":"2024-01-14T21:19:48.127955Z","shell.execute_reply":"2024-01-14T21:19:48.127096Z","shell.execute_reply.started":"2024-01-14T21:19:22.770529Z"},"trusted":true},"outputs":[],"source":["train_eng_texts = [pair[0] for pair in text_pairs]  #Change text_pairs to train_pairs if I want to use the train-test-val split\n","train_fre_texts = [pair[1] for pair in text_pairs]\n","\n","eng_vectorization.adapt(train_eng_texts) #fitting the text vectorization layer to data\n","fre_vectorization.adapt(train_fre_texts) #same (but unchanged data)"]},{"cell_type":"markdown","metadata":{},"source":["### Downloading the vectorizers"]},{"cell_type":"code","execution_count":96,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T22:21:20.554445Z","iopub.status.busy":"2024-01-14T22:21:20.553443Z","iopub.status.idle":"2024-01-14T22:21:20.706104Z","shell.execute_reply":"2024-01-14T22:21:20.705155Z","shell.execute_reply.started":"2024-01-14T22:21:20.554411Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['text_vectorizer_fr_20k-vocab20.joblib']"]},"execution_count":96,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"This cell downloads the two TextVectorizer that were trained on our text data\"\"\"\n","##(déjà fait pour vocab_size=15000 et sentence_length=14)\n","## Sauvegarder le vectorizer anglais ##\n","\n","# eng_vectorization_data = {\n","#     'config': eng_vectorization.get_config(),\n","#     'weights': eng_vectorization.get_weights()\n","# }\n","# joblib.dump(eng_vectorization_data, 'text_vectorizer_eng_20k-vocab20.joblib')\n","\n","# # Sauvegarder le vectorizer français ##\n","# fre_vectorization_data = {\n","#     'config': fre_vectorization.get_config(),\n","#     'weights': fre_vectorization.get_weights()\n","# }\n","# joblib.dump(fre_vectorization_data, 'text_vectorizer_fr_20k-vocab20.joblib')\n"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T21:19:48.138009Z","iopub.status.busy":"2024-01-14T21:19:48.137663Z","iopub.status.idle":"2024-01-14T21:19:48.234401Z","shell.execute_reply":"2024-01-14T21:19:48.233502Z","shell.execute_reply.started":"2024-01-14T21:19:48.137964Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["french vocab:  20000\n","english vocab:  14341\n","[start] is considered as a single token: True\n"]}],"source":["# Get the vocabulary of the text vectorization layer\n","vocabulary = fre_vectorization.get_vocabulary()\n","print(\"french vocab: \", len(vocabulary))\n","print(\"english vocab: \", len(eng_vectorization.get_vocabulary()))\n","\n","# vocab_size = min(len(eng_vectorization.get_vocabulary()), len(vocabulary))\n","\n","# Check if \"[start]\" is in the vocabulary\n","is_start_token_in_vocab = \"[start]\" in vocabulary\n","\n","# Print the result\n","print(f\"[start] is considered as a single token: {is_start_token_in_vocab}\")"]},{"cell_type":"markdown","metadata":{},"source":["# **IV. Model Definition & Training**"]},{"cell_type":"markdown","metadata":{},"source":["## **IV.1 Applying Vectorizers, Padding sequences, Encoder-Decoder Definition**\n","### Encoder input\n","Encoder Input: Sequences of English tokens (sentences) represented as integer indices."]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T21:19:48.242595Z","iopub.status.busy":"2024-01-14T21:19:48.242334Z","iopub.status.idle":"2024-01-14T21:22:50.097925Z","shell.execute_reply":"2024-01-14T21:22:50.096872Z","shell.execute_reply.started":"2024-01-14T21:19:48.242573Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Incoder pad_sequences execution time : 180.66\n"]}],"source":["# Data preparation ( stripping, tokenization and vectorization(indexing) )\n","train_eng_sequences = eng_vectorization(train_eng_texts)\n","# Pad the sequences to the specified sequence length\n","start = time.time()\n","encoder_input_data = pad_sequences(train_eng_sequences, maxlen=sequence_length, padding=\"post\")\n","end = time.time()\n","print(f\"Incoder pad_sequences execution time : {end - start:.2f}\")"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T21:22:50.099250Z","iopub.status.busy":"2024-01-14T21:22:50.098985Z","iopub.status.idle":"2024-01-14T21:22:50.105197Z","shell.execute_reply":"2024-01-14T21:22:50.104354Z","shell.execute_reply.started":"2024-01-14T21:22:50.099228Z"},"trusted":true},"outputs":[{"data":{"text/plain":["20"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["len(encoder_input_data[0])"]},{"cell_type":"markdown","metadata":{},"source":["### Decoder input\n","Decoder Input: Sequences of french sentences represented as integer indices.\n","SHIFTED BY 1 POSITION !"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T21:22:50.106541Z","iopub.status.busy":"2024-01-14T21:22:50.106293Z","iopub.status.idle":"2024-01-14T21:25:51.238689Z","shell.execute_reply":"2024-01-14T21:25:51.237730Z","shell.execute_reply.started":"2024-01-14T21:22:50.106520Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["decoder pad_sequences execution time : 179.87\n"]}],"source":["# Data preparation\n","train_fre_sequences = fre_vectorization(train_fre_texts)\n","# Shift the target french sentences by one position (decoder input)\n","decoder_input_data = train_fre_sequences[:, :-1]\n","# Pad the sequences to the specified sequence length (+1 for the start token)\n","# decoder_input_data = pad_sequences(decoder_input_data, maxlen=sequence_length + 1, padding=\"post\")\n","start = time.time()\n","decoder_input_data = pad_sequences(decoder_input_data, maxlen=sequence_length, padding=\"post\")\n","end = time.time()\n","print(f\"decoder pad_sequences execution time : {end - start:.2f}\")"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T21:25:51.240352Z","iopub.status.busy":"2024-01-14T21:25:51.239990Z","iopub.status.idle":"2024-01-14T21:25:51.246959Z","shell.execute_reply":"2024-01-14T21:25:51.246017Z","shell.execute_reply.started":"2024-01-14T21:25:51.240320Z"},"trusted":true},"outputs":[{"data":{"text/plain":["20"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["len(decoder_input_data[0])"]},{"cell_type":"markdown","metadata":{},"source":["### Decoder Output\n","\n","Decoder Output: Target French sentences (with hiding the first token). \\\n","N.B : I won't one-hot encode these sentences and use Categorical Crossentropy loss. To make it less expensive, I'll let tokens represented with indicies and I'll use Sparse Categorical Crossentropy"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T21:25:51.248397Z","iopub.status.busy":"2024-01-14T21:25:51.248099Z","iopub.status.idle":"2024-01-14T21:25:51.264173Z","shell.execute_reply":"2024-01-14T21:25:51.263228Z","shell.execute_reply.started":"2024-01-14T21:25:51.248362Z"},"trusted":true},"outputs":[{"data":{"text/plain":["20"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"One-hot encoded representations can be an alternative (very expensive)\"\"\"\n","\n","# # One-hot encode the target french sentences (decoder output)\n","# decoder_output_data = to_categorical(train_fre_sequences[:, 1:], num_classes=vocab_size)\n","\n","# decoder_output_data = decoder_output_data[:, :sequence_length + 1, :]  # Adjust the sequence length\n","decoder_output_data = train_fre_sequences[:, 1:]\n","len(decoder_output_data[0])"]},{"cell_type":"markdown","metadata":{},"source":["## **IV.2 Model Definition**"]},{"cell_type":"markdown","metadata":{},"source":["#### Model parameters"]},{"cell_type":"code","execution_count":97,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T22:34:03.668135Z","iopub.status.busy":"2024-01-14T22:34:03.667684Z","iopub.status.idle":"2024-01-14T22:34:03.672790Z","shell.execute_reply":"2024-01-14T22:34:03.672043Z","shell.execute_reply.started":"2024-01-14T22:34:03.668104Z"},"trusted":true},"outputs":[],"source":["embed_dim = 256 #should be equal to embed_dim (useless for now)\n","latent_dim = 176\n","batch_size = 128  \n","epochs = 46  \n","num_encoder_tokens = vocab_size  #max vocab of the original dataset (df_raw) for english is around 14.5k (around 30k for french)\n","num_decoder_tokens = vocab_size"]},{"cell_type":"code","execution_count":98,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T22:34:05.808342Z","iopub.status.busy":"2024-01-14T22:34:05.807512Z","iopub.status.idle":"2024-01-14T22:34:05.812219Z","shell.execute_reply":"2024-01-14T22:34:05.811263Z","shell.execute_reply.started":"2024-01-14T22:34:05.808310Z"},"trusted":true},"outputs":[],"source":["##Variant (word2Vec for embedding then untrainable embedding layer). (Cf. NLP from 0 to 1 : text classification and M.translation: Medium)\n","\n","# embedding_layer = Embedding(vocab_size, 150, weights=[embedding_vectors], input_length=max_length, trainable=False)\n","# model = Sequential()\n","# model.add(embedding_layer)\n","# model.add(Dropout(0.2))"]},{"cell_type":"code","execution_count":99,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T22:34:10.273404Z","iopub.status.busy":"2024-01-14T22:34:10.272738Z","iopub.status.idle":"2024-01-14T22:34:10.802048Z","shell.execute_reply":"2024-01-14T22:34:10.801242Z","shell.execute_reply.started":"2024-01-14T22:34:10.273374Z"},"trusted":true},"outputs":[],"source":["# Need to have inputs = integer sequences (representing sequences of words, encoded by their index in a dictionary)\n","\n","# model.compile(optimizer='rmsprop', loss='categorical_crossentropy')  #if decoder_output_data was one-hot encoded\n","\n","# with strategy.scope():    #only if TPUs are used\n","    \n","# Define an input sequence and process it.\n","encoder_inputs = Input(shape=(None,))\n","x = Embedding(num_encoder_tokens, latent_dim)(encoder_inputs)\n","x, state_h, state_c = LSTM(latent_dim,\n","                           return_state=True)(x)\n","x = Dropout(0.3)(x)  # Add dropout layer to the encoder\n","\n","encoder_states = [state_h, state_c]\n","\n","# Set up the decoder, using `encoder_states` as initial state.\n","decoder_inputs = Input(shape=(None,))\n","x = Embedding(num_decoder_tokens, latent_dim)(decoder_inputs)\n","x = LSTM(latent_dim, return_sequences=True)(x, initial_state=encoder_states)\n","x = Dropout(0.3)(x)  # Add dropout layer to the decoder\n","decoder_outputs = Dense(num_decoder_tokens, activation='softmax')(x)\n","\n","# Define the model that will turn\n","# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","# Compile the model with sparse categorical crossentropy\n","optimizer = RMSprop(learning_rate=0.002)\n","model.compile(optimizer=optimizer, loss=sparse_categorical_crossentropy)\n","\n","    "]},{"cell_type":"code","execution_count":100,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T22:34:11.956615Z","iopub.status.busy":"2024-01-14T22:34:11.956266Z","iopub.status.idle":"2024-01-14T22:34:11.987178Z","shell.execute_reply":"2024-01-14T22:34:11.986301Z","shell.execute_reply.started":"2024-01-14T22:34:11.956588Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_3 (InputLayer)        [(None, None)]               0         []                            \n","                                                                                                  \n"," input_4 (InputLayer)        [(None, None)]               0         []                            \n","                                                                                                  \n"," embedding_2 (Embedding)     (None, None, 176)            3520000   ['input_3[0][0]']             \n","                                                                                                  \n"," embedding_3 (Embedding)     (None, None, 176)            3520000   ['input_4[0][0]']             \n","                                                                                                  \n"," lstm_2 (LSTM)               [(None, 176),                248512    ['embedding_2[0][0]']         \n","                              (None, 176),                                                        \n","                              (None, 176)]                                                        \n","                                                                                                  \n"," lstm_3 (LSTM)               (None, None, 176)            248512    ['embedding_3[0][0]',         \n","                                                                     'lstm_2[0][1]',              \n","                                                                     'lstm_2[0][2]']              \n","                                                                                                  \n"," dropout_3 (Dropout)         (None, None, 176)            0         ['lstm_3[0][0]']              \n","                                                                                                  \n"," dense_1 (Dense)             (None, None, 20000)          3540000   ['dropout_3[0][0]']           \n","                                                                                                  \n","==================================================================================================\n","Total params: 11077024 (42.26 MB)\n","Trainable params: 11077024 (42.26 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["## **IV.3 Launching Training**"]},{"cell_type":"code","execution_count":101,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T22:34:23.916351Z","iopub.status.busy":"2024-01-14T22:34:23.915980Z","iopub.status.idle":"2024-01-14T23:10:12.636009Z","shell.execute_reply":"2024-01-14T23:10:12.635013Z","shell.execute_reply.started":"2024-01-14T22:34:23.916321Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/46\n","1029/1029 [==============================] - 66s 61ms/step - loss: 2.2171 - val_loss: 1.9392\n","Epoch 2/46\n","1029/1029 [==============================] - 47s 46ms/step - loss: 1.8122 - val_loss: 1.6863\n","Epoch 3/46\n","1029/1029 [==============================] - 47s 45ms/step - loss: 1.6291 - val_loss: 1.5452\n","Epoch 4/46\n","1029/1029 [==============================] - 47s 45ms/step - loss: 1.5127 - val_loss: 1.4599\n","Epoch 5/46\n","1029/1029 [==============================] - 47s 45ms/step - loss: 1.4149 - val_loss: 1.3462\n","Epoch 6/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 1.3288 - val_loss: 1.2630\n","Epoch 7/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 1.2522 - val_loss: 1.1994\n","Epoch 8/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 1.1837 - val_loss: 1.1368\n","Epoch 9/46\n","1029/1029 [==============================] - 47s 45ms/step - loss: 1.1232 - val_loss: 1.0837\n","Epoch 10/46\n","1029/1029 [==============================] - 47s 45ms/step - loss: 1.0698 - val_loss: 1.0407\n","Epoch 11/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 1.0210 - val_loss: 0.9996\n","Epoch 12/46\n","1029/1029 [==============================] - 47s 45ms/step - loss: 0.9787 - val_loss: 0.9624\n","Epoch 13/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.9414 - val_loss: 0.9408\n","Epoch 14/46\n","1029/1029 [==============================] - 47s 45ms/step - loss: 0.9072 - val_loss: 0.9046\n","Epoch 15/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.8760 - val_loss: 0.8808\n","Epoch 16/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.8481 - val_loss: 0.8604\n","Epoch 17/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.8225 - val_loss: 0.8421\n","Epoch 18/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.7988 - val_loss: 0.8289\n","Epoch 19/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.7769 - val_loss: 0.8097\n","Epoch 20/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.7560 - val_loss: 0.8011\n","Epoch 21/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.7369 - val_loss: 0.7904\n","Epoch 22/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.7191 - val_loss: 0.7830\n","Epoch 23/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.7023 - val_loss: 0.7666\n","Epoch 24/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.6862 - val_loss: 0.7586\n","Epoch 25/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.6708 - val_loss: 0.7480\n","Epoch 26/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.6566 - val_loss: 0.7432\n","Epoch 27/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.6425 - val_loss: 0.7358\n","Epoch 28/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.6296 - val_loss: 0.7285\n","Epoch 29/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.6179 - val_loss: 0.7218\n","Epoch 30/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.6056 - val_loss: 0.7145\n","Epoch 31/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.5941 - val_loss: 0.7110\n","Epoch 32/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.5829 - val_loss: 0.7092\n","Epoch 33/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.5727 - val_loss: 0.7013\n","Epoch 34/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.5625 - val_loss: 0.6995\n","Epoch 35/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.5529 - val_loss: 0.6929\n","Epoch 36/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.5435 - val_loss: 0.6893\n","Epoch 37/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.5341 - val_loss: 0.6882\n","Epoch 38/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.5254 - val_loss: 0.6845\n","Epoch 39/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.5167 - val_loss: 0.6851\n","Epoch 40/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.5094 - val_loss: 0.6826\n","Epoch 41/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.5015 - val_loss: 0.6782\n","Epoch 42/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.4932 - val_loss: 0.6764\n","Epoch 43/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.4864 - val_loss: 0.6756\n","Epoch 44/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.4796 - val_loss: 0.6718\n","Epoch 45/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.4723 - val_loss: 0.6705\n","Epoch 46/46\n","1029/1029 [==============================] - 46s 45ms/step - loss: 0.4657 - val_loss: 0.6706\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x7fc07397f850>"]},"execution_count":101,"metadata":{},"output_type":"execute_result"}],"source":["model.fit([encoder_input_data, decoder_input_data], decoder_output_data,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          validation_split=0.18,\n","          verbose=1)\n","# strategy.run(replica_fn, args=dist_batch)"]},{"cell_type":"markdown","metadata":{},"source":["# **V. Inference:**\n","##### Encoder Input: A single English sentence represented as integer indices.\n","##### Decoder Input: A start-of-sequence token (initially) and subsequently predicted tokens (Recurrency).\n","##### Decoder Output: Predicted probabilities for the next word in the sequence."]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T22:09:57.647532Z","iopub.status.busy":"2024-01-14T22:09:57.646641Z","iopub.status.idle":"2024-01-14T22:09:57.655920Z","shell.execute_reply":"2024-01-14T22:09:57.654994Z","shell.execute_reply.started":"2024-01-14T22:09:57.647501Z"},"trusted":true},"outputs":[],"source":["def translate_sentence(model, eng_text, eng_vectorization, fre_vectorization, sequence_length):\n","    \n","    # Tokenize and pad the English input sentence\n","    eng_sequence = eng_vectorization(np.array([eng_text]))\n","    eng_sequence = pad_sequences(eng_sequence, maxlen=sequence_length, padding=\"post\")\n","\n","    # Initialize the decoder input with the start token\n","    fre_sequence = np.zeros((1, sequence_length), dtype=np.int32)\n","    fre_sequence[0, 0] = fre_vectorization.get_vocabulary().index('[start]')\n","\n","    # Inference loop\n","    for i in range(1, sequence_length):\n","        predictions = model.predict([eng_sequence, fre_sequence])\n","        predicted_token_index = np.argmax(predictions[0, i - 1, :])\n","        fre_sequence[0, i] = predicted_token_index\n","\n","        # Check for the end token\n","        if fre_vectorization.get_vocabulary()[predicted_token_index] == '[end]':\n","            break\n","\n","    # Convert the predicted indices to French text\n","    translated_text = ' '.join([fre_vectorization.get_vocabulary()[idx] for idx in fre_sequence[0] if idx > 0])\n","    if not(\"[end]\" in translated_text):\n","        translated_text+=\" [end]\"\n","    \n","    #further processing (without the trained model) of the sentence....\n","    # to think about (ex. change cest with c'est in the french sentence)  (renverse preprocessing)\n","    \n","\n","    return translated_text\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["#### **Inference tests of the trained Model**"]},{"cell_type":"code","execution_count":94,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T22:19:03.226595Z","iopub.status.busy":"2024-01-14T22:19:03.226201Z","iopub.status.idle":"2024-01-14T22:19:03.986831Z","shell.execute_reply":"2024-01-14T22:19:03.985879Z","shell.execute_reply.started":"2024-01-14T22:19:03.226568Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Translated Sentence (current model):  [start] cest très beau [end]\n"]}],"source":["#test before saving\n","# Example usage\n","eng_text_to_translate = \"It's very beautiful\" \n","translated_sentence = translate_sentence(model, eng_text_to_translate, eng_vectorization, fre_vectorization, sequence_length)\n","print(\"Translated Sentence (current model): \", translated_sentence)"]},{"cell_type":"markdown","metadata":{},"source":["### Saving the trained model :\n","##### Be careful to save only after complete training and getting good performances"]},{"cell_type":"code","execution_count":95,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T22:19:22.922606Z","iopub.status.busy":"2024-01-14T22:19:22.921754Z","iopub.status.idle":"2024-01-14T22:19:23.058796Z","shell.execute_reply":"2024-01-14T22:19:23.058023Z","shell.execute_reply.started":"2024-01-14T22:19:22.922570Z"},"trusted":true},"outputs":[],"source":["# Save the model\n","model.save('my_translation_model_gpu_v80.h5')"]},{"cell_type":"markdown","metadata":{},"source":["### Loading a model for inference"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T15:18:07.077102Z","iopub.status.busy":"2024-01-14T15:18:07.076699Z","iopub.status.idle":"2024-01-14T15:18:07.082732Z","shell.execute_reply":"2024-01-14T15:18:07.081805Z","shell.execute_reply.started":"2024-01-14T15:18:07.077058Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['tabdelimited-englisharabic-sentence-pairs', 'translation-of-sentences-in-different-languages', 'my-model-v6-0-97-val-loss-and-0-3-train-loss']\n"]}],"source":["from tensorflow.keras.models import load_model\n","import os\n","print(os.listdir('/kaggle/input'))"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T20:28:01.031959Z","iopub.status.busy":"2024-01-11T20:28:01.031205Z","iopub.status.idle":"2024-01-11T20:28:03.291128Z","shell.execute_reply":"2024-01-11T20:28:03.290289Z","shell.execute_reply.started":"2024-01-11T20:28:01.031926Z"},"trusted":true},"outputs":[],"source":["# Load the model for inference\n","# model_v01 = load_model('my_translation_model_v01.h5')\n","\n","# model_gpu_v02 = load_model('my_translation_model_gpu_v02.h5')   #big (20k vocab and 50 epochs, 32min of training with cpu+1gpu)\n","# model_gpu_v3 = load_model('my_translation_model_gpu_v3')   #big (14k vocab and 35 epochs, 18min of training with cpu+1gpu, lr=0.005, 0.2 train_loss/ 1.01 val_loss/ 512 latent dim) : not bad nor good\n","\n","# model_gpu_v6 = load_model('my_translation_model_gpu_v6.h5')   #big (14k vocab and 30 epochs, .... of training with cpu+1gpu, lr=0.001, 0.41 train_loss/ 0.97 val_loss/ 256 latent dim) Impression : not bad\n","\n","#model_gpu_v7     #Big : 20k vocab, 27 epochs, gpu, lr=0.02, 0.6 train_loss, 0.93 val_loss, 256 embedding/hidden, dropout(0.2)\n","\n","model_gpu_v6 = load_model('/kaggle/input/my-model-v6-0-97-val-loss-and-0-3-train-loss/my_translation_model_gpu_v6.h5') \n","\n","\n","# model_v03 = load_model('my_translation_model_v03')  #medium (10k vocab and 40 epochs, less than 10min of training with CPUs)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-03T22:43:14.039029Z","iopub.status.busy":"2024-01-03T22:43:14.038322Z","iopub.status.idle":"2024-01-03T22:43:14.042827Z","shell.execute_reply":"2024-01-03T22:43:14.041971Z","shell.execute_reply.started":"2024-01-03T22:43:14.038996Z"},"trusted":true},"outputs":[],"source":["# # Example usage\n","# eng_text_to_translate = \"Try to translate this\"\n","# translated_sentence = translate_sentence(model_gpu_v02, eng_text_to_translate, eng_vectorization, fre_vectorization, sequence_length)\n","# print(\"Translated Sentence (gpu_v02): \", translated_sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-03T22:46:24.618862Z","iopub.status.busy":"2024-01-03T22:46:24.618210Z","iopub.status.idle":"2024-01-03T22:46:25.790938Z","shell.execute_reply":"2024-01-03T22:46:25.789620Z","shell.execute_reply.started":"2024-01-03T22:46:24.618829Z"},"trusted":true},"outputs":[],"source":["# Example usage\n","eng_text_to_translate = \"This is a test sequence\"\n","translated_sentence = translate_sentence(model_gpu_v6, eng_text_to_translate, eng_vectorization, fre_vectorization, sequence_length)\n","print(\"Translated Sentence (gpu_v6): \", translated_sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T19:53:56.126205Z","iopub.status.busy":"2024-01-14T19:53:56.125797Z","iopub.status.idle":"2024-01-14T19:53:56.164614Z","shell.execute_reply":"2024-01-14T19:53:56.163373Z","shell.execute_reply.started":"2024-01-14T19:53:56.126168Z"},"trusted":true},"outputs":[],"source":["\"\"\"Checking if a specific word is in vocabulary\"\"\"\n","vocab_fra = fre_vectorization.get_vocabulary()\n","vocab_eng = eng_vectorization.get_vocabulary()\n","print(len(vocab_eng))\n","'test' in vocab_eng"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# \"\"\" Proposition for adapting this model by integrating transformers\"\"\"\n","# import tensorflow as tf\n","# from tensorflow import keras\n","# from tensorflow.keras import layers\n","\n","# # ... (code remains unchanged)\n","\n","# # Encoder\n","# encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n","# encoder_embedding = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)(encoder_inputs)\n","# encoder_lstm = layers.LSTM(latent_dim, return_state=True)\n","# encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n","# encoder_states = [state_h, state_c]\n","\n","# encoder = keras.Model(encoder_inputs, encoder_states)\n","\n","# # Decoder\n","# decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n","# decoder_embedding = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)(decoder_inputs)\n","# decoder_lstm = layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n","# decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n","# decoder_dense = layers.Dense(vocab_size, activation=\"softmax\")\n","# decoder_outputs = decoder_dense(decoder_outputs)\n","\n","# decoder = keras.Model(decoder_inputs, decoder_outputs)\n","\n","# # Model\n","# decoder_outputs = decoder(decoder_inputs)\n","# lstm_transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs, name=\"lstm_transformer\")\n","\n","# # ... (code remains unchanged)\n","\n","# # Training the model\n","# lstm_transformer.summary()\n","# lstm_transformer.compile(\n","#     \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n","# )\n","# lstm_transformer.fit(train_ds, epochs=epochs, validation_data=val_ds)\n","\n","# # ... (code remains unchanged)\n","\n","# # Decoding test sentences\n","# fre_vocab = fre_vectorization.get_vocabulary()\n","# fre_index_lookup = dict(zip(range(len(fre_vocab)), fre_vocab))\n","# max_decoded_sentence_length = 20\n","\n","# # ... (code remains unchanged)\n"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":64315,"sourceId":128696,"sourceType":"datasetVersion"},{"datasetId":2669072,"sourceId":4575591,"sourceType":"datasetVersion"},{"datasetId":4257237,"sourceId":7333476,"sourceType":"datasetVersion"}],"dockerImageVersionId":30628,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":4}
